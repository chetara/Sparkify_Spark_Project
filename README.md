# ğŸ§ Sparkify ETL Project (PySpark)

This project builds a **data pipeline using Apache Spark** to process song and log data for Sparkify, a fictional music streaming service. The result is a set of **analytically useful tables** written in Parquet format, structured in a star schema.

---

## ğŸ“ Project Structure

```bash
Sparkify_spark_project/
â”œâ”€â”€ data/                  # Raw input data (songs & logs)
â”‚   â”œâ”€â”€ song_data/
â”‚   â””â”€â”€ log_data/
â”œâ”€â”€ etl/                   # ETL pipeline scripts
â”‚   â”œâ”€â”€ test.py
â”‚   â”œâ”€â”€ load_data.py
â”‚   â”œâ”€â”€ transform_songs.py
â”‚   â”œâ”€â”€ transform_users.py
â”‚   â”œâ”€â”€ build_songplays.py
â”œâ”€â”€ outputs/               # Output folder for Parquet tables
â”œâ”€â”€ .venv/                 # Python virtual environment (excluded from git)
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # This file

``` 

## ğŸš€ What It Does
âœ… Reads raw JSON files of song and log data

âœ… Cleans and transforms the data using PySpark

âœ… Creates a star schema of tables:

songs (dimension)

artists (dimension)

users (dimension)

time (dimension)

songplays (fact table)

âœ… Writes each table in Parquet format for efficient querying

## ğŸ› ï¸ Technologies Used

Tool	Purpose
Python 3.10+	Core programming language
PySpark 3.x	Distributed data processing & transformation
Hadoop 3.3.1	Required for file I/O on Windows (via winutils.exe)
Parquet	Columnar output format for performance
Local filesystem	Storage backend (easily extendable to AWS)

## âš ï¸ Windows Setup Fix: Native Hadoop Error
If you get this error when reading many files:


``` bash

java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0
âœ… Solution

```