# Sparkify ETL Project (PySpark)

This project builds a **data pipeline using Apache Spark** to process song and log data for Sparkify, a fictional music streaming service. The result is a set of **analytically useful tables** written in Parquet format, structured in a star schema.

## My data sources:

### **Song Dataset**
Songs dataset is a subset of [Million Song Dataset](http://millionsongdataset.com/).

Sample Record :
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```

### **Log Dataset**
Logs dataset is generated by [Event Simulator](https://github.com/Interana/eventsim).

Sample Record :
```
{"artist": null, "auth": "Logged In", "firstName": "Walter", "gender": "M", "itemInSession": 0, "lastName": "Frye", "length": null, "level": "free", "location": "San Francisco-Oakland-Hayward, CA", "method": "GET","page": "Home", "registration": 1540919166796.0, "sessionId": 38, "song": null, "status": 200, "ts": 1541105830796, "userAgent": "\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"", "userId": "39"}
```

### Files used on the project:

```bash
Sparkify_spark_project/
├── data/                  # Raw input data (songs & logs)
│   ├── song_data/
│   └── log_data/
├── etl/                   # ETL pipeline scripts
│   ├── test.py
│   ├── load_data.py
│   ├── transform_songs.py
│   ├── transform_users.py
│   ├── build_songplays.py
├── outputs/               # Output folder for Parquet tables
├── .venv/                 # Python virtual environment (excluded from git)
├── requirements.txt       # Python dependencies
└── README.md              # This file


### What It Does

This project is a full data engineering pipeline that:

✅ Reads raw JSON files of song and log data

✅ Cleans and transforms the data using PySpark

✅ Creates a star schema of the following tables:

songs (dimension)

artists (dimension)

users (dimension)

time (dimension)

songplays (fact table)

✅ Writes each table in Parquet format for optimized analytics

✅ Can be extended to run on AWS S3 + Redshift